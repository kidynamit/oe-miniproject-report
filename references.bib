@article{RefWorks:32,	author={Catherine Chavula and C. Maria Keet},	year={2014},	title={Is lemon Sufficient for Building Multilingual Ontologies for Bantu Languages?}}@article{RefWorks:36,	author={M. Horridge and N. Drummond and J. Goodwin and A. Rector and R. Stevens and H. Wang},	journal={The Manchester OWL syntax.2006; OWL: Experiences and Directions (OWLED 06): Athens, Georgia: CEUR}}@inproceedings{RefWorks:33,	author={Kaarel Kaljurand and Norbert E. Fuchs},	year={2007},	title={Verbalizing OWL in Attempto Controlled English.},	booktitle={OWLED},	volume={258}}@inbook{RefWorks:35,	author={C. Maria Keet and Langa Khumalo},	year={2014},	title={Basics for a grammar engine to verbalize logical theories in isiZulu},	series={Rules on the Web. From Theory to Applications},	publisher={Springer},	pages={216-225}}@inbook{RefWorks:34,	author={Holger Knublauch and Ray W. Fergerson and Natalya F. Noy and Mark A. Musen},	year={2004},	title={The Protégé OWL plugin: An open development environment for semantic web applications},	series={The Semantic Web–ISWC 2004},	publisher={Springer},	pages={229-243}}@article{RefWorks:29,	author={Alice H. Oh and Alexander I. Rudnicky},	year={2002},	month={0},	title={Stochastic natural language generation for spoken dialog systems},	journal={Computer Speech & Language},	volume={16},	number={3–4},	pages={387-407},	abstract={We describe a corpus-based approach to natural language generation (NLG). The approach has been implemented as a component of a spoken dialog system and a series of evaluations were carried out. Our system uses n-gram language models, which have been found useful in other language technology applications, in a generative mode. It is not yet clear whether the simple n-grams can adequately model human language generation in general, but we show that we can successfully apply this ubiquitous modeling technique to the task of natural language generation for spoken dialog systems. In this paper, we discuss applying corpus-based stochastic language generation at two levels: content selection and sentence planning/realization. At the content selection level, output utterances are modeled by bigrams, and the appropriate attributes are chosen using bigram statistics. In sentence planning and realization, corpus utterances are modeled by n-grams of varying length, and new utterances are generated stochastically. Through this work, we show that a simple statistical model alone can generate appropriate language for a spoken dialog system. The results describe a promising avenue for using a statistical approach in future NLG systems.},	isbn={0885-2308}}@inproceedings{RefWorks:30,	author={Rolf Schwitter and Kaarel Kaljurand and Anne Cregan and Catherine Dolbear and Glen Hart},	year={2008},	title={A comparison of three controlled natural languages for OWL 1.1},	booktitle={4th OWL Experiences and Directions Workshop (OWLED 2008 DC), Washington},	pages={1-2}}